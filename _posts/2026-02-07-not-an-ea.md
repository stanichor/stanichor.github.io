---
layout: post
title: "I Guess I'm Not An EA?"
date: 2026-02-07
permalink: /not-an-ea/
categories: 
---

I think doing good is good. And doing good effectively allows more good to be done, which is even more good. As this is the central thesis of EA, it seems like I'm in agreement with them on the core issue. Despite this, something I've noticed is that whenever there's a difference between the effective altruists and the rationalists, I always seem to end up on the side of the rationalists. I don't have a theory that explains this; it's just an interesting pattern I've noticed. I don't know why this is, but it's an interesting phenomenon. Let me share some examples.

Going through the [demographic data,](https://stanichor.net/rat-demographics/) the rats are more atheistic than the EAs; I happen to be an atheist. The rats are also more libertarian and less liberal than the EAs; of the top four US political parties, if I had to choose one, it would be the Libertarian Party. And if I've learned anything from taking [political ideology quizzes](https://stanichor.net/political-quiz-1/), it's that I'm not as liberal as I once thought.

Someone once said “the number of EA moral realists is frighteningly high” in response to [EigenGender's tweet](https://x.com/EigenGender/status/1990547613700272385) that “the most stigmatized belief you can hold in rat circles is moral realism,” and I also side with the rats on this.

When I look at posts that have been crossposted to both the EA Forum and LessWrong, I end up agreeing with LessWrong's opinion[^opinion] of the posts more often[^often] than the EA Forum's opinion. Off the top of my head, the posts of Bentham's Bulldog come to mind. I was going to bring up specific posts, but just the fact that he doesn't seem to have any negative-karma posts on the EA Forum while having many on LessWrong says enough. I think he's very wrong oftentimes, and it seems like LessWrong agrees while the EA Forum doesn't. More generally, I think it's valuable, when a post is egregiously wrong, for there to be comments that explicitly point this out and explain why. I see this much more often on LessWrong than on the EA Forum.

Speaking of forums, when I look at the custom emojis each forum uses, I feel that this also tracks the difference. LessWrong feels like a place I want to spend more time on, while the EA Forum's emojis are just… bland.

<div style="text-align: center;">
    <figure>
        <img src="/assets/images/not-an-ea/ea-forum-emojis.png" width="200" alt="Alt text">
        <img src="/assets/images/not-an-ea/lesswrong-emojis.png" width="238" alt="Alt text">
    </figure>
</div>

What explains all these differences? I don't know. The only [work I know of on determining what psychological traits predict interest in effective altruism](https://forum.effectivealtruism.org/posts/7f3sq7ZHcRsaBBeMD/what-psychological-traits-predict-interest-in-effective) concluded that the most important traits were… “effectiveness-focus” and “expansive altruism”; so, the E and the A in EA. Unfortunately, this doesn't really speak to the differences I'm pointing at here, namely differences in epistemic style, norms around disagreement, or broader cultural fit, and it doesn't touch on the psychological differences between the rats and the EAs.

Anyways, the following photo is a pretty good litmus test for whether you side with the EAs or the rats: do you regard this man with respect, or disgust? By now, you can guess which one I do.

<div style="text-align: center;">
    <figure>
        <img src="/assets/images/not-an-ea/yud.png" width="500" alt="Alt text">
    </figure>
</div>

[^opinion]: As expressed via comments and post karma

[^often]: By 'often', I mean in every case I can remember